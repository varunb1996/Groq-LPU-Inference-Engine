{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc0df1-7e38-4686-bc4f-c61a7b28e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install llama-index\n",
    "%pip install llama-index-llms-groq\n",
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a65c01-dfb1-4a39-87ef-cb518b08a4e7",
   "metadata": {},
   "source": [
    "Setting up the LLM using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae93914-bcca-49e8-a2dc-1bfa001b91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "import os\n",
    "\n",
    "llm = \n",
    "Groq(model=\"llama3-70b-8192\",api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7986575-0a58-4ff1-ad88-ce077de73aa8",
   "metadata": {},
   "source": [
    "Setting up an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccc19e-31ca-4fcd-946f-c7669f11a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = \n",
    "HuggingFaceEmbedding(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be7545-a15a-459e-8319-d7224a3dc3d3",
   "metadata": {},
   "source": [
    "Global settings configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cad821d-573c-441b-8755-a3d1feab125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b6394-b1ff-40c1-9eaf-41954e83f537",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545568e9-d1fc-40e8-9a35-4af11e83ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "de_tools_blog = SimpleDirectoryReader(\"./\",required_exts=[\".pdf\", \".docx\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73196cb-f09d-4df3-9fac-af02392b6b1c",
   "metadata": {},
   "source": [
    "Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e4415-adee-45ad-9d56-822d35206dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(de_tools_blog)\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "response = query_engine.query(\"How many tools are there?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4c4da-1087-4b1f-9c5d-9ed24c92f90a",
   "metadata": {},
   "source": [
    "RAG chat engine with history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698ab41-8325-4453-bbf9-20f6eb3bde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(    \n",
    "   index.as_retriever(),    \n",
    "   memory=memory,    \n",
    "   llm=llm\n",
    ")\n",
    "\n",
    "response = chat_engine.chat(    \n",
    "   \"What tools are suitable for data processing?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1eb74f-5147-405d-964c-e688060ed055",
   "metadata": {},
   "source": [
    "Testing memory of the chat engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a676f-0f97-4fb8-8d79-80e6cfcea489",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_engine.chat(\n",
    "    \"Can you create a diagram of a data pipeline using these tools?\"\n",
    ")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
